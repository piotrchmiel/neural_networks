Accuracy 0.7669903635978699 Cost 0.0813392159761861 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 1000
Accuracy 0.7666869759559631 Cost 0.0840968422126025 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 700
Accuracy 0.7645632028579712 Cost 0.08599037368549034 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 400
Accuracy 0.7627427577972412 Cost 0.08705170976463705 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 500
Accuracy 0.7609224319458008 Cost 0.08918807131703943 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 400
Accuracy 0.7606189846992493 Cost 0.08422335085924715 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 500
Accuracy 0.7594053745269775 Cost 0.08147097285836935 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 700
Accuracy 0.7591020464897156 Cost 0.08234479965176433 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 700
Accuracy 0.7578884363174438 Cost 0.08526331378379837 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 500
Accuracy 0.7572816610336304 Cost 0.08913163491524756 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 1000
Accuracy 0.7563714981079102 Cost 0.08589663059683517 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 700
Accuracy 0.7557647228240967 Cost 0.08725029870402068 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 400
Accuracy 0.7551578283309937 Cost 0.08783766737906262 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 1000
Accuracy 0.7548544406890869 Cost 0.0800272295018658 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 1000
Accuracy 0.7548544406890869 Cost 0.09140813566045836 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 1000
Accuracy 0.754551112651825 Cost 0.08993399830069393 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 300
Accuracy 0.7545510530471802 Cost 0.08946642756927758 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 1000
Accuracy 0.7536408305168152 Cost 0.08873728866456077 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 300
Accuracy 0.753337562084198 Cost 0.07914842432364821 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 1000
Accuracy 0.7527307271957397 Cost 0.08909396757371724 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 500
Accuracy 0.752730667591095 Cost 0.08835855172947049 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 1000
Accuracy 0.7527306079864502 Cost 0.08986942662158981 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 1000
Accuracy 0.7521238327026367 Cost 0.08264553564367816 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 1000
Accuracy 0.7521238327026367 Cost 0.09144154150271788 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 700
Accuracy 0.75182044506073 Cost 0.0854110008222051 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 1000
Accuracy 0.7518203854560852 Cost 0.09157358336960897 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 1000
Accuracy 0.7503035068511963 Cost 0.09129227948142216 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 400
Accuracy 0.749696671962738 Cost 0.09211233182577416 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 300
Accuracy 0.7472695112228394 Cost 0.09319893404608592 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 700
Accuracy 0.7460558414459229 Cost 0.08890730794519186 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 700
Accuracy 0.7457525134086609 Cost 0.09392539173131809 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 1000
Accuracy 0.7457525134086609 Cost 0.092851031513419 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 700
Accuracy 0.7448423504829407 Cost 0.09366678982041776 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 1000
Accuracy 0.7442355155944824 Cost 0.0940402434207499 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 200
Accuracy 0.743628740310669 Cost 0.09289125091163442 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 200
Accuracy 0.7436286807060242 Cost 0.09190626390045509 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 1000
Accuracy 0.7433253526687622 Cost 0.0948336495202966 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 700
Accuracy 0.7418083548545837 Cost 0.09155665576690808 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 700
Accuracy 0.741504967212677 Cost 0.09221514035016298 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 500
Accuracy 0.7408981323242188 Cost 0.09347846457967535 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 700
Accuracy 0.7378642559051514 Cost 0.09440260304836556 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 400
Accuracy 0.7372573614120483 Cost 0.09430856938706711 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 300
Accuracy 0.7369539737701416 Cost 0.0949124296894297 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 500
Accuracy 0.7366505265235901 Cost 0.0950019495212473 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 700
Accuracy 0.7360438108444214 Cost 0.09620366670424119 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 1000
Accuracy 0.7351336479187012 Cost 0.09500098880380392 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 500
Accuracy 0.7345268130302429 Cost 0.09662326920079067 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 500
Accuracy 0.7336165904998779 Cost 0.09621565992711112 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 200
Accuracy 0.7327064871788025 Cost 0.07455686753382906 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 100
Accuracy 0.7305826544761658 Cost 0.0970267930533737 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 1000
Accuracy 0.7305826544761658 Cost 0.09675556136062369 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 1000
Accuracy 0.7302792072296143 Cost 0.07953259826172143 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 50
Accuracy 0.7299758791923523 Cost 0.09551209927303717 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 700
Accuracy 0.7299758195877075 Cost 0.0974296770291403 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 700
Accuracy 0.7290656566619873 Cost 0.09662057319656014 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 500
Accuracy 0.7272452116012573 Cost 0.09709755249787122 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 500
Accuracy 0.7269417643547058 Cost 0.09859274607151747 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 500
Accuracy 0.7263350486755371 Cost 0.09766627551289275 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 700
Accuracy 0.7248180508613586 Cost 0.09752906253561378 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 400
Accuracy 0.7245146632194519 Cost 0.09752020053565502 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 400
Accuracy 0.7242112159729004 Cost 0.08903085300698876 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 20
Accuracy 0.7242112159729004 Cost 0.0986773605691269 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 400
Accuracy 0.721480667591095 Cost 0.09850492770783603 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 500
Accuracy 0.721177339553833 Cost 0.0986470699426718 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 200
Accuracy 0.7208738327026367 Cost 0.0990026833023876 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 400
Accuracy 0.7202670574188232 Cost 0.0976855150074698 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 300
Accuracy 0.719356894493103 Cost 0.1010874910862185 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 400
Accuracy 0.7181433439254761 Cost 0.10009611636633053 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 700
Accuracy 0.7169296741485596 Cost 0.0992398212547414 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 500
Accuracy 0.7148059010505676 Cost 0.08715793100418523 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 50
Accuracy 0.7145025730133057 Cost 0.070788286277093 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 400
Accuracy 0.7135922908782959 Cost 0.1012835503788665 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 500
Accuracy 0.7135922312736511 Cost 0.09959749440895393 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 400
Accuracy 0.7132889032363892 Cost 0.09825617296155542 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 10
Accuracy 0.7129855155944824 Cost 0.10031381784938276 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 100
Accuracy 0.7120752930641174 Cost 0.10061175003647804 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 300
Accuracy 0.7120752334594727 Cost 0.07199321989901364 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 200
Accuracy 0.7117719650268555 Cost 0.10046676715137437 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 300
Accuracy 0.711468517780304 Cost 0.10124820208875462 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 500
Accuracy 0.7111651301383972 Cost 0.10073364980053157 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 700
Accuracy 0.7105583548545837 Cost 0.07114660931983963 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 300
Accuracy 0.7105583548545837 Cost 0.10093011445133016 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 1000
Accuracy 0.709344744682312 Cost 0.07010644656838849 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 700
Accuracy 0.709344744682312 Cost 0.10163819376612082 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 400
Accuracy 0.7090413570404053 Cost 0.10103355313185602 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 400
Accuracy 0.7081311941146851 Cost 0.10149665002245456 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 1000
Accuracy 0.7078277468681335 Cost 0.07035290583735332 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 500
Accuracy 0.7063107490539551 Cost 0.10065705666784197 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 700
Accuracy 0.7041869759559631 Cost 0.10231431701686233 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 300
Accuracy 0.7032767534255981 Cost 0.10262916184728965 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 300
Accuracy 0.7032767534255981 Cost 0.10175576276378706 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 300
Accuracy 0.7029733657836914 Cost 0.10157721443101764 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 100
Accuracy 0.7017598152160645 Cost 0.06991137843579054 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.01, Training Epoches: 1000
Accuracy 0.7008495926856995 Cost 0.10402671940391883 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 300
Accuracy 0.700546145439148 Cost 0.07811564859002829 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 200
Accuracy 0.6999394297599792 Cost 0.1020395492669195 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 200
Accuracy 0.6987258195877075 Cost 0.10373450646875426 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 500
Accuracy 0.6984224319458008 Cost 0.07567783974809572 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 700
Accuracy 0.6975122094154358 Cost 0.10356482706265524 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 400
Accuracy 0.6969053745269775 Cost 0.07691471552243456 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 300
Accuracy 0.6966019868850708 Cost 0.10384692595107481 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 100
Accuracy 0.6962986588478088 Cost 0.07640192069811746 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 400
Accuracy 0.6953884363174438 Cost 0.10347302723675966 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 400
Accuracy 0.6947816610336304 Cost 0.07513753062812611 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 1000
Accuracy 0.6938714385032654 Cost 0.0817866786965169 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 100
Accuracy 0.6920510530471802 Cost 0.10440712474519387 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 1000
Accuracy 0.69114089012146 Cost 0.10368732240749523 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 1000
Accuracy 0.6908373832702637 Cost 0.10423961078049615 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 500
Accuracy 0.6902306079864502 Cost 0.07624466868583113 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 500
Accuracy 0.6899272799491882 Cost 0.10405839112354442 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 500
Accuracy 0.6899272799491882 Cost 0.10419215075671673 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 300
Accuracy 0.6890170574188232 Cost 0.10505891899811104 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 200
Accuracy 0.687196671962738 Cost 0.10432887857314199 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 1000
Accuracy 0.686286449432373 Cost 0.09741566149750724 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 20
Accuracy 0.6856796741485596 Cost 0.10491396166617051 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 300
Accuracy 0.6844661235809326 Cost 0.10494631342589855 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 700
Accuracy 0.6841627359390259 Cost 0.10475928912637755 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 200
Accuracy 0.6838592886924744 Cost 0.1051073360722512 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 700
Accuracy 0.6832525134086609 Cost 0.1060785244917497 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 400
Accuracy 0.6790049076080322 Cost 0.10627209569793195 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 200
Accuracy 0.6787015199661255 Cost 0.10701255028834566 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 200
Accuracy 0.6787015199661255 Cost 0.106606850924436 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 300
Accuracy 0.676274299621582 Cost 0.10657078039366752 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 400
Accuracy 0.6738471388816833 Cost 0.10673723457148299 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 300
Accuracy 0.6738471388816833 Cost 0.10677322145784274 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 400
Accuracy 0.6735437512397766 Cost 0.10652311373269185 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 200
Accuracy 0.6717234253883362 Cost 0.10613344720331952 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 100
Accuracy 0.6699029207229614 Cost 0.10787999571766704 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 50
Accuracy 0.669296145439148 Cost 0.10832377831684425 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 200
Accuracy 0.6671724319458008 Cost 0.10761155042564496 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 700
Accuracy 0.6659588813781738 Cost 0.1081305340048857 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 700
Accuracy 0.6656554341316223 Cost 0.10838531813351437 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 500
Accuracy 0.6632282137870789 Cost 0.10867439955472946 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 500
Accuracy 0.6626214385032654 Cost 0.1079235085635446 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 700
Accuracy 0.6623180508613586 Cost 0.10828296956606209 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 200
Accuracy 0.6604976654052734 Cost 0.10836747597204521 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 1000
Accuracy 0.658980667591095 Cost 0.10905579308746383 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 50
Accuracy 0.6583738923072815 Cost 0.10861395602114499 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 1000
Accuracy 0.6568568348884583 Cost 0.10905745177296922 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 200
Accuracy 0.6565534472465515 Cost 0.10919463826576248 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 300
Accuracy 0.6529127359390259 Cost 0.11064601154066622 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 50
Accuracy 0.6523059010505676 Cost 0.10926890518749133 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 300
Accuracy 0.6513956785202026 Cost 0.09724462521262467 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 500
Accuracy 0.6513956785202026 Cost 0.09523547108983621 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 700
Accuracy 0.6510922908782959 Cost 0.10918451804900542 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 100
Accuracy 0.6504855155944824 Cost 0.11044631956610829 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 400
Accuracy 0.6501821279525757 Cost 0.11078456859104335 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 400
Accuracy 0.6492719650268555 Cost 0.10935407172655687 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 300
Accuracy 0.6486651301383972 Cost 0.11076831503305584 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 200
Accuracy 0.648058295249939 Cost 0.09346150903729722 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 1000
Accuracy 0.646844744682312 Cost 0.11064148746663705 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 200
Accuracy 0.6465412974357605 Cost 0.11071247642394155 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 500
Accuracy 0.6432039737701416 Cost 0.09911307302536443 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 300
Accuracy 0.6425971388816833 Cost 0.11132780835032463 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 500
Accuracy 0.6410802006721497 Cost 0.11192197049967945 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 100
Accuracy 0.6404733657836914 Cost 0.11158851586515084 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 700
Accuracy 0.6398665904998779 Cost 0.11181157227838412 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 100
Accuracy 0.6389563679695129 Cost 0.11129922268446535 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 500
Accuracy 0.638046145439148 Cost 0.09767953510163352 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 400
Accuracy 0.636832594871521 Cost 0.10605157515965402 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.02, Training Epoches: 10
Accuracy 0.6322816014289856 Cost 0.11305589193943888 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 300
Accuracy 0.6313714385032654 Cost 0.10327181417960674 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 200
Accuracy 0.6313713788986206 Cost 0.11199315160047263 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 700
Accuracy 0.6310679912567139 Cost 0.11323608236853033 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 400
Accuracy 0.6310679912567139 Cost 0.11281993839656934 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 50
Accuracy 0.6304612159729004 Cost 0.11341296060709283 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 100
Accuracy 0.6304612159729004 Cost 0.11327724170405418 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 300
Accuracy 0.6295510530471802 Cost 0.11295126745244488 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 200
Accuracy 0.6292476654052734 Cost 0.11333641118835658 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 400
Accuracy 0.6292476058006287 Cost 0.11256225808756426 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 400
Accuracy 0.6277306079864502 Cost 0.11322060972452164 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 100
Accuracy 0.6262136697769165 Cost 0.11275007098447531 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 100
Accuracy 0.6259102821350098 Cost 0.0972721777507104 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 400
Accuracy 0.624696671962738 Cost 0.11325443652458489 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 200
Accuracy 0.6243932247161865 Cost 0.09541751648066565 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 700
Accuracy 0.6237865090370178 Cost 0.11276861885562539 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 1000
Accuracy 0.6234830617904663 Cost 0.11327769071795046 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 200
Accuracy 0.6225728988647461 Cost 0.09432617423590273 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 1000
Accuracy 0.6219661235809326 Cost 0.09894625208107755 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 300
Accuracy 0.6219660639762878 Cost 0.09654701343970373 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 500
Accuracy 0.6171117424964905 Cost 0.11480454338015988 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 1000
Accuracy 0.6155946850776672 Cost 0.11483663314720616 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 1000
Accuracy 0.6137743592262268 Cost 0.10725794913014397 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 100
Accuracy 0.6131675243377686 Cost 0.11471004883060232 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 500
Accuracy 0.6125607490539551 Cost 0.11474407522473484 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 100
Accuracy 0.6119539737701416 Cost 0.11469174432568252 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 500
Accuracy 0.6119539737701416 Cost 0.11440224188845605 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 100
Accuracy 0.6113471984863281 Cost 0.11529843823518604 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 100
Accuracy 0.6098301410675049 Cost 0.10218251263722777 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 200
Accuracy 0.6095267534255981 Cost 0.11583129968494177 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 300
Accuracy 0.6092233657836914 Cost 0.11524056148482487 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 300
Accuracy 0.6080097556114197 Cost 0.11551878222962841 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 50
Accuracy 0.6070995926856995 Cost 0.11553363566054031 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 300
Accuracy 0.6067962050437927 Cost 0.11618907121010125 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 20
Accuracy 0.6049758195877075 Cost 0.11065985111054033 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 100
Accuracy 0.6037622094154358 Cost 0.11649037175811827 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 100
Accuracy 0.6007282137870789 Cost 0.11653556913370267 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 200
Accuracy 0.6007282137870789 Cost 0.11686766392085701 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 200
Accuracy 0.6001214385032654 Cost 0.11573499738005921 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 700
Accuracy 0.5998180508613586 Cost 0.11670899140881374 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 100
Accuracy 0.5979976654052734 Cost 0.11663448222680017 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 400
Accuracy 0.5976942777633667 Cost 0.10725381167139858 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 1000
Accuracy 0.596480667591095 Cost 0.11672934633679688 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 400
Accuracy 0.5928398966789246 Cost 0.11776249087415636 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 700
Accuracy 0.5928398370742798 Cost 0.11726049310527742 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 20
Accuracy 0.592536449432373 Cost 0.11792736040661111 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 50
Accuracy 0.5907161235809326 Cost 0.10879250982543454 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 700
Accuracy 0.5895024538040161 Cost 0.11804880981799215 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 700
Accuracy 0.5882889032363892 Cost 0.1179364796844311 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 50
Accuracy 0.5879855155944824 Cost 0.11288373783463612 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 50
Accuracy 0.5837379097938538 Cost 0.11875189724378288 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 200
Accuracy 0.5831311345100403 Cost 0.11941296537406743 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 50
Accuracy 0.5828277468681335 Cost 0.11877201939933002 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 20
Accuracy 0.5822209119796753 Cost 0.1190806595259346 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 200
Accuracy 0.5819175243377686 Cost 0.11859996878774837 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 500
Accuracy 0.5816141366958618 Cost 0.11916190816555172 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 50
Accuracy 0.5800971388816833 Cost 0.11905152309918776 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 100
Accuracy 0.5794903039932251 Cost 0.11872759618563578 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 1000
Accuracy 0.5791869759559631 Cost 0.1189166404074058 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 100
Accuracy 0.5788835883140564 Cost 0.11915343487635255 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 300
Accuracy 0.5776699781417847 Cost 0.11900827614590526 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 100
Accuracy 0.5764563679695129 Cost 0.1192306843586266 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 200
Accuracy 0.5758496522903442 Cost 0.1192869558581151 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 300
Accuracy 0.5755462050437927 Cost 0.11872194736497477 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 50
Accuracy 0.575546145439148 Cost 0.11280537355924025 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 400
Accuracy 0.573119044303894 Cost 0.11160348198609427 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 500
Accuracy 0.5716019868850708 Cost 0.12079537269892171 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 500
Accuracy 0.5697816014289856 Cost 0.11425455048447475 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 300
Accuracy 0.5679612159729004 Cost 0.12118398380698636 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 20
Accuracy 0.5664442181587219 Cost 0.121025143598672 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 500
Accuracy 0.5640170574188232 Cost 0.12056499219033867 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 50
Accuracy 0.5634102821350098 Cost 0.12063026707619429 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 400
Accuracy 0.5606796741485596 Cost 0.12256420584162697 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.7, Training Epoches: 10
Accuracy 0.5606796145439148 Cost 0.12098774150945246 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 50
Accuracy 0.5567355155944824 Cost 0.12138721096562222 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 50
Accuracy 0.5540049076080322 Cost 0.12308109691366553 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 1000
Accuracy 0.5533981323242188 Cost 0.12227660225471482 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 700
Accuracy 0.553094744682312 Cost 0.12292947852984071 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 100
Accuracy 0.5515776872634888 Cost 0.12002718664007261 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 50
Accuracy 0.5482403635978699 Cost 0.1229477942106314 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 1000
Accuracy 0.5470267534255981 Cost 0.12308480916544795 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 400
Accuracy 0.5464199781417847 Cost 0.12302052590530366 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 400
Accuracy 0.5464199185371399 Cost 0.1237984939943999 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 20
Accuracy 0.5464199185371399 Cost 0.12304652779130265 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 50
Accuracy 0.5461165308952332 Cost 0.12284509441815317 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 50
Accuracy 0.5452063679695129 Cost 0.12331015180097893 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 100
Accuracy 0.5436893701553345 Cost 0.1230395189486444 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 200
Accuracy 0.5418689846992493 Cost 0.11945964343613014 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 200
Accuracy 0.5394417643547058 Cost 0.12444010114995763 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.6, Training Epoches: 10
Accuracy 0.5376213788986206 Cost 0.12355250050313771 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 300
Accuracy 0.5370146036148071 Cost 0.12316259858198464 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 200
Accuracy 0.5336772203445435 Cost 0.12027613597456366 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 20
Accuracy 0.5297331213951111 Cost 0.12615545192966238 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.5, Training Epoches: 10
Accuracy 0.5285195112228394 Cost 0.12654438457684591 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 50
Accuracy 0.5263956785202026 Cost 0.12723022501450032 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 700
Accuracy 0.523968517780304 Cost 0.12610300234518945 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 500
Accuracy 0.5236650705337524 Cost 0.1261493394849822 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 50
Accuracy 0.5236650705337524 Cost 0.1256745122373104 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 100
Accuracy 0.5224515199661255 Cost 0.12636097153881565 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 300
Accuracy 0.5206310749053955 Cost 0.12579945469042286 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 50
Accuracy 0.5197209119796753 Cost 0.12618294631829485 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 100
Accuracy 0.5166869759559631 Cost 0.12620254431385547 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 300
Accuracy 0.5166869163513184 Cost 0.12747121386928484 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 20
Accuracy 0.5142597556114197 Cost 0.12649797316407785 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 100
Accuracy 0.5112258195877075 Cost 0.127613426244352 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 20
Accuracy 0.5087985992431641 Cost 0.127142988902051 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 700
Accuracy 0.5069781541824341 Cost 0.12834639241918921 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 200
Accuracy 0.5063713788986206 Cost 0.12804268568288535 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 20
Accuracy 0.49848300218582153 Cost 0.12948030891129747 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 20
Accuracy 0.4966626763343811 Cost 0.12869607959873974 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 400
Accuracy 0.4945388734340668 Cost 0.128563079982996 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 20
Accuracy 0.49332529306411743 Cost 0.12922451744088903 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.4, Training Epoches: 10
Accuracy 0.49150487780570984 Cost 0.12958732369588688 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 20
Accuracy 0.4857403039932251 Cost 0.13156034820713103 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 1000
Accuracy 0.4814927577972412 Cost 0.1318595395423472 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 500
Accuracy 0.4805825650691986 Cost 0.13048562576295808 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 400
Accuracy 0.4793689548969269 Cost 0.12864375754725188 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 500
Accuracy 0.4742112159729004 Cost 0.1318040382466279 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 200
Accuracy 0.4726942181587219 Cost 0.13155340705998242 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 50
Accuracy 0.4717840552330017 Cost 0.13167039887048304 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 1000
Accuracy 0.4714806079864502 Cost 0.13197635050164536 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 20
Accuracy 0.47057044506073 Cost 0.13186326384311542 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 20
Accuracy 0.47057044506073 Cost 0.1315520919742994 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 500
Accuracy 0.469660222530365 Cost 0.13185248628724366 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 100
Accuracy 0.4681432247161865 Cost 0.12683869764441624 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.05, Training Epoches: 10
Accuracy 0.4681432247161865 Cost 0.13267247611656785 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.3, Training Epoches: 10
Accuracy 0.4672330617904663 Cost 0.13190999784274027 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 100
Accuracy 0.46571606397628784 Cost 0.13211721769766882 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 50
Accuracy 0.465109258890152 Cost 0.1316483596456237 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 200
Accuracy 0.4645024538040161 Cost 0.121128311206121 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 1000
Accuracy 0.4626820981502533 Cost 0.12766396068036556 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 700
Accuracy 0.45873787999153137 Cost 0.12617752427468076 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 1000
Accuracy 0.4581311047077179 Cost 0.1326823469134979 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 300
Accuracy 0.4563107490539551 Cost 0.13246140402043238 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 20
Accuracy 0.4544903337955475 Cost 0.13445626269094646 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.01, Training Epoches: 10
Accuracy 0.44781556725502014 Cost 0.13530621922109276 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 400
Accuracy 0.44265779852867126 Cost 0.13507185399066657 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 50
Accuracy 0.4423544108867645 Cost 0.1354730762541294 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 20
Accuracy 0.43992722034454346 Cost 0.13500314974226058 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 400
Accuracy 0.4368932247161865 Cost 0.13505308597814292 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 20
Accuracy 0.4323422610759735 Cost 0.1369294881587848 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 700
Accuracy 0.4311286509037018 Cost 0.13625442667398602 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 50
Accuracy 0.42991507053375244 Cost 0.13223702571121976 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 100
Accuracy 0.42748787999153137 Cost 0.1324003886547871 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 300
Accuracy 0.4268810749053955 Cost 0.13829035765957087 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.7, Training Epoches: 10
Accuracy 0.4241505265235901 Cost 0.12336733657866716 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 500
Accuracy 0.418082594871521 Cost 0.13701299845706671 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 700
Accuracy 0.41383498907089233 Cost 0.1361923523945734 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 50
Accuracy 0.412621408700943 Cost 0.13864232623018324 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.7, Training Epoches: 10
Accuracy 0.41049763560295105 Cost 0.12218250799924135 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 700
Accuracy 0.40776699781417847 Cost 0.13200445141410455 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 100
Accuracy 0.4044296443462372 Cost 0.13935360894538462 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 20
Accuracy 0.402609258890152 Cost 0.13860167132224888 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 100
Accuracy 0.40230584144592285 Cost 0.13920471910387278 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.2, Training Epoches: 10
Accuracy 0.40048545598983765 Cost 0.12439724704017863 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 400
Accuracy 0.40048545598983765 Cost 0.13982824911363423 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 300
Accuracy 0.39714810252189636 Cost 0.13962538435589522 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 300
Accuracy 0.39350730180740356 Cost 0.14065961341839284 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.6, Training Epoches: 10
Accuracy 0.3929005265235901 Cost 0.12572427926352248 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 300
Accuracy 0.38986653089523315 Cost 0.13935597508680075 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 20
Accuracy 0.3892597556114197 Cost 0.1403967518126592 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 20
Accuracy 0.3892597258090973 Cost 0.12727551546413451 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 200
Accuracy 0.3886529505252838 Cost 0.13928757270332426 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 200
Accuracy 0.38622575998306274 Cost 0.14124777354300022 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.6, Training Epoches: 10
Accuracy 0.38349518179893494 Cost 0.13718062726547942 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 50
Accuracy 0.37651699781417847 Cost 0.14225798705592752 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 500
Accuracy 0.3704490661621094 Cost 0.1423895109910518 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 500
Accuracy 0.3686286509037018 Cost 0.14269795827567577 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 100
Accuracy 0.3658980429172516 Cost 0.14264854381326586 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 50
Accuracy 0.36013349890708923 Cost 0.1459344601025805 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 700
Accuracy 0.3561893403530121 Cost 0.13814810902113095 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 200
Accuracy 0.3555825352668762 Cost 0.14772775617893785 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 500
Accuracy 0.3546723425388336 Cost 0.14210975053720176 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 100
Accuracy 0.35406553745269775 Cost 0.14306431845761836 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.5, Training Epoches: 10
Accuracy 0.3528519570827484 Cost 0.14352908020373434 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.15, Training Epoches: 10
Accuracy 0.3519417941570282 Cost 0.14293209777679294 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.5, Training Epoches: 10
Accuracy 0.3516383767127991 Cost 0.14510290266480297 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 1000
Accuracy 0.34769418835639954 Cost 0.1362240906455554 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 500
Accuracy 0.3464806079864502 Cost 0.1429117270745337 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 50
Accuracy 0.3419296443462372 Cost 0.13822427636478096 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 300
Accuracy 0.3410194218158722 Cost 0.13749226205982268 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 400
Accuracy 0.3355582356452942 Cost 0.1455250805011019 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 400
Accuracy 0.33252429962158203 Cost 0.1460772118298337 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.4, Training Epoches: 10
Accuracy 0.3304004967212677 Cost 0.13502918893937021 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 700
Accuracy 0.3270631432533264 Cost 0.14560238423291594 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 400
Accuracy 0.3258495330810547 Cost 0.14566839463077486 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 20
Accuracy 0.3252427279949188 Cost 0.14578913408331573 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 200
Accuracy 0.322512149810791 Cost 0.1460673997644335 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 200
Accuracy 0.31826457381248474 Cost 0.14619959332048893 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 20
Accuracy 0.3070388436317444 Cost 0.14640469220466912 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.4, Training Epoches: 10
Accuracy 0.3055218458175659 Cost 0.15417351783253253 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 300
Accuracy 0.3037014603614807 Cost 0.14266553847119212 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 50
Accuracy 0.3000607192516327 Cost 0.14876820659264922 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 20
Accuracy 0.2997572720050812 Cost 0.14406727137975395 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 100
Accuracy 0.29854369163513184 Cost 0.15311455121263862 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 400
Accuracy 0.29611650109291077 Cost 0.1346537686767988 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 1000
Accuracy 0.28731799125671387 Cost 0.1492317069787532 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 300
Accuracy 0.2848907709121704 Cost 0.1500763059593737 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 20
Accuracy 0.2794296145439148 Cost 0.1495292552281171 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.3, Training Epoches: 10
Accuracy 0.27730584144592285 Cost 0.1408326830714941 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 200
Accuracy 0.26729369163513184 Cost 0.1484795946162194 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 50
Accuracy 0.26547330617904663 Cost 0.14942048431839794 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 300
Accuracy 0.26395630836486816 Cost 0.14443337626289576 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 20
Accuracy 0.26304614543914795 Cost 0.1480910301906988 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 100
Accuracy 0.26183250546455383 Cost 0.14934722008183599 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 20
Accuracy 0.2587985396385193 Cost 0.14914635999593884 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.1, Training Epoches: 10
Accuracy 0.2572815716266632 Cost 0.149233057978563 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 100
Accuracy 0.25667476654052734 Cost 0.15061072388198227 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.3, Training Epoches: 10
Accuracy 0.24544905126094818 Cost 0.1585978427901864 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 200
Accuracy 0.24211165308952332 Cost 0.15159671497531235 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 50
Accuracy 0.23240292072296143 Cost 0.15158490790054202 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 50
Accuracy 0.21996361017227173 Cost 0.1508957858895883 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.1, Training Epoches: 10
Accuracy 0.20661407709121704 Cost 0.15353157930076122 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 200
Accuracy 0.20206312835216522 Cost 0.16028551198542118 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 20
Accuracy 0.19781553745269775 Cost 0.154310415382497 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 100
Accuracy 0.19781552255153656 Cost 0.15448154066689312 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 20
Accuracy 0.19447816908359528 Cost 0.15415468928404152 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 20
Accuracy 0.19296115636825562 Cost 0.1540681760525331 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.2, Training Epoches: 10
Accuracy 0.19235438108444214 Cost 0.15387405350338668 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 200
Accuracy 0.18992717564105988 Cost 0.15353512985166162 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 100
Accuracy 0.1893204003572464 Cost 0.15433373278938234 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.2, Training Epoches: 10
Accuracy 0.18234221637248993 Cost 0.19746228121221066 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 1000
Accuracy 0.18173544108867645 Cost 0.14927962073124945 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 20
Accuracy 0.17991504073143005 Cost 0.15368209953885525 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 700
Accuracy 0.17930825054645538 Cost 0.18749643105547875 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 400
Accuracy 0.1750606894493103 Cost 0.15597437252290547 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.05, Training Epoches: 10
Accuracy 0.17445389926433563 Cost 0.17373226210474968 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 700
Accuracy 0.17081309854984283 Cost 0.1644458199152723 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 10
Accuracy 0.16899272799491882 Cost 0.1541166672250256 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 500
Accuracy 0.1650485396385193 Cost 0.1810027362080291 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 700
Accuracy 0.16413834691047668 Cost 0.15625814732629806 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 400
Accuracy 0.16413834691047668 Cost 0.15611904789693654 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.15, Training Epoches: 10
Accuracy 0.16262134909629822 Cost 0.1570288217626512 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.15, Training Epoches: 10
Accuracy 0.16049757599830627 Cost 0.16931611043401062 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 100
Accuracy 0.15473300218582153 Cost 0.15621590393129736 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 50
Accuracy 0.15139564871788025 Cost 0.15359378524590284 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 300
Accuracy 0.14441747963428497 Cost 0.15276281838305295 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 1000
Accuracy 0.13895632326602936 Cost 0.18614928110037 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 1000
Accuracy 0.13895632326602936 Cost 0.1767849411116913 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 1000
Accuracy 0.13804611563682556 Cost 0.17408120422624052 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 500
Accuracy 0.13683253526687622 Cost 0.15223939949646592 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.15, Training Epoches: 50
Accuracy 0.13410194218158722 Cost 0.17580619605723768 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 200
Accuracy 0.13197816908359528 Cost 0.1847841093549505 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 200
Accuracy 0.12985436618328094 Cost 0.19957290787715465 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 500
Accuracy 0.12894417345523834 Cost 0.1975832706084475 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 300
Accuracy 0.12803398072719574 Cost 0.15705956949386746 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 20
Accuracy 0.12378640472888947 Cost 0.19778939220122993 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 400
Accuracy 0.1231796145439148 Cost 0.1593305537244305 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 200
Accuracy 0.12287621200084686 Cost 0.19749010144732893 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 200
Accuracy 0.11771845817565918 Cost 0.16452515090350062 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 50
Accuracy 0.11589805781841278 Cost 0.15884937881492078 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 20
Accuracy 0.11589805036783218 Cost 0.1554583419347182 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.02, Training Epoches: 10
Accuracy 0.11559466272592545 Cost 0.22557223367039114 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 300
Accuracy 0.11468446254730225 Cost 0.1593227863777429 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 50
Accuracy 0.11438106000423431 Cost 0.18579810915980488 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 700
Accuracy 0.1098301038146019 Cost 0.185927142505534 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 50
Accuracy 0.10922330617904663 Cost 0.15835749346297234 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 50
Accuracy 0.10861650854349136 Cost 0.15948565409053117 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.1, Training Epoches: 10
Accuracy 0.10770631581544876 Cost 0.17505179904401302 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 300
Accuracy 0.10770631581544876 Cost 0.19529372919350863 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 500
Accuracy 0.10527912527322769 Cost 0.16673374036327004 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 20
Accuracy 0.10315534472465515 Cost 0.1838772501796484 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 100
Accuracy 0.10315534472465515 Cost 0.18080046586692333 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 300
Accuracy 0.09951455891132355 Cost 0.1591885668458417 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.1, Training Epoches: 10
Accuracy 0.09890776872634888 Cost 0.17474465095438063 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 400
Accuracy 0.09860437363386154 Cost 0.1586151592200622 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 20
Accuracy 0.09860436618328094 Cost 0.15872338449116796 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 100
Accuracy 0.096480593085289 Cost 0.5633435670752078 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 300
Accuracy 0.09344659745693207 Cost 0.2218669494614005 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 100
Accuracy 0.09314320236444473 Cost 0.2666386979399249 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 10
Accuracy 0.09253641217947006 Cost 0.5428894853685051 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 1000
Accuracy 0.08950242400169373 Cost 0.22100976284127682 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 700
Accuracy 0.08495146036148071 Cost 0.15902809100225568 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 100
Accuracy 0.08373786509037018 Cost 0.2437832709401846 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 400
Accuracy 0.08282766491174698 Cost 0.5380529572721571 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 50
Accuracy 0.0785800889134407 Cost 0.17635563854128122 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 10
Accuracy 0.07645630836486816 Cost 0.1727164532057941 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 1000
Accuracy 0.07402912527322769 Cost 0.16223468026146293 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 50
Accuracy 0.07402912527322769 Cost 0.17436999350320548 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 50
Accuracy 0.07372572273015976 Cost 0.5174639208707958 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 100
Accuracy 0.07281553745269775 Cost 1.2967786150984466 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 400
Accuracy 0.07251213490962982 Cost 0.5726331765763462 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 400
Accuracy 0.07160194218158722 Cost 1.1816418133676052 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 500
Accuracy 0.07160194218158722 Cost 0.16367318795528263 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 20
Accuracy 0.07099515199661255 Cost 0.5589906245004386 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 700
Accuracy 0.07069174945354462 Cost 0.1609975666506216 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 20
Accuracy 0.06856796145439148 Cost 0.5957421348430216 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 10
Accuracy 0.06796116381883621 Cost 0.17854416475165635 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 500
Accuracy 0.06765776127576828 Cost 0.20253349875565618 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 10
Accuracy 0.06523057818412781 Cost 0.16061681183055043 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.02, Training Epoches: 10
Accuracy 0.06492718309164047 Cost 0.18603930610697716 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.3, Training Epoches: 20
Accuracy 0.06462378799915314 Cost 0.16282038937788457 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 20
Accuracy 0.06371359527111053 Cost 0.1617844463326037 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.05, Training Epoches: 10
Accuracy 0.05976942181587219 Cost 0.2202421537367627 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 50
Accuracy 0.05825243145227432 Cost 0.16162454837467521 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.05, Training Epoches: 10
Accuracy 0.058252427726984024 Cost 0.16180637862998992 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 20
Accuracy 0.05612863972783089 Cost 0.16156422428321093 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 50
Accuracy 0.055521853268146515 Cost 0.2130021823104471 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 20
Accuracy 0.05339806154370308 Cost 0.160361843300052 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.2, Training Epoches: 100
Accuracy 0.05309465900063515 Cost 0.6640375899150968 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 700
Accuracy 0.05248786509037018 Cost 0.22200022218748927 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 100
Accuracy 0.05066747963428497 Cost 1.276232789736241 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 50
Accuracy 0.050060681998729706 Cost 1.163718307390809 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 100
Accuracy 0.049150481820106506 Cost 0.1664754565572366 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.05, Training Epoches: 10
Accuracy 0.048543691635131836 Cost 1.2017203494906425 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 700
Accuracy 0.0473300963640213 Cost 1.1996587626636028 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 300
Accuracy 0.047026701271533966 Cost 0.16196347237564623 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 50
Accuracy 0.046723298728466034 Cost 0.6844559712335467 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 50
Accuracy 0.046723298728466034 Cost 0.1974510276922956 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 50
Accuracy 0.0464199036359787 Cost 0.24192310497164726 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 200
Accuracy 0.04581310600042343 Cost 0.1648568307282403 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.02, Training Epoches: 10
Accuracy 0.045509714633226395 Cost 0.2386718241032213 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.4, Training Epoches: 20
Accuracy 0.045509710907936096 Cost 0.6733822498936206 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 100
Accuracy 0.04520631581544876 Cost 0.16315038804896176 Optimizer <class 'tensorflow.python.training.adagrad.AdagradOptimizer'> Learning Rate 0.01, Training Epoches: 10
Accuracy 0.04520631209015846 Cost 0.5676177376881242 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 500
Accuracy 0.04490291327238083 Cost 0.16376729181502014 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.02, Training Epoches: 10
Accuracy 0.041565533727407455 Cost 0.6727393763139844 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 300
Accuracy 0.04095873981714249 Cost 0.16358908009715378 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 20
Accuracy 0.04065534099936485 Cost 0.17112538043875247 Optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'> Learning Rate 0.01, Training Epoches: 10
Accuracy 0.03944174945354462 Cost 1.2060316512361169 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 200
Accuracy 0.03913835063576698 Cost 0.6051939909812063 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 20
Accuracy 0.03489077836275101 Cost 0.22907905373722315 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.15, Training Epoches: 10
Accuracy 0.03458737954497337 Cost 0.7156714289449155 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 1000
Accuracy 0.03428398072719574 Cost 0.18166997923981398 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 20
Accuracy 0.03428398072719574 Cost 0.5682025356218219 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 700
Accuracy 0.033980581909418106 Cost 1.1518928236328065 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 700
Accuracy 0.032463595271110535 Cost 0.6673102374188602 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 200
Accuracy 0.0321601964533329 Cost 0.4958070679567754 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 50
Accuracy 0.0321601964533329 Cost 0.5640754229389131 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 300
Accuracy 0.0321601964533329 Cost 0.7626757845282555 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 100
Accuracy 0.0321601927280426 Cost 1.4822769216261804 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 20
Accuracy 0.03185679763555527 Cost 0.6795606745872647 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 500
Accuracy 0.03185679391026497 Cost 0.6542748480569571 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 400
Accuracy 0.03124999813735485 Cost 0.6206516914535314 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 500
Accuracy 0.03124999813735485 Cost 1.1142274290323257 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 100
Accuracy 0.030643204227089882 Cost 0.5133141160476953 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 10
Accuracy 0.030643204227089882 Cost 1.5606877249665558 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 10
Accuracy 0.030643204227089882 Cost 1.441630600951612 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 50
Accuracy 0.030643202364444733 Cost 1.1885509178973734 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 20
Accuracy 0.030339807271957397 Cost 0.39858056732919067 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 300
Accuracy 0.030036406591534615 Cost 0.43290997738949955 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 1000
Accuracy 0.02973301336169243 Cost 1.192513382062316 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 1000
Accuracy 0.029429610818624496 Cost 0.24059166968800128 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 50
Accuracy 0.029429610818624496 Cost 1.2464651810005307 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 200
Accuracy 0.029429610818624496 Cost 1.360895611345768 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 100
Accuracy 0.029429610818624496 Cost 1.3896227991208434 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 400
Accuracy 0.028822816908359528 Cost 0.5098502938635647 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 20
Accuracy 0.02882281504571438 Cost 0.5392435637768358 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 100
Accuracy 0.028519418090581894 Cost 0.5467667288612574 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 20
Accuracy 0.028519416227936745 Cost 1.4021707898937166 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 20
Accuracy 0.02821602299809456 Cost 1.2098355991765857 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 1000
Accuracy 0.02821602113544941 Cost 0.7409895048476756 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 1000
Accuracy 0.02821601927280426 Cost 0.5948799019679427 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.6, Training Epoches: 200
Accuracy 0.02821601927280426 Cost 0.44808274088427424 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 700
Accuracy 0.02821601927280426 Cost 0.7027402229141444 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 20
Accuracy 0.02821601927280426 Cost 0.6996380188502371 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 50
Accuracy 0.02821601927280426 Cost 1.1896532918326557 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 1000
Accuracy 0.02821601927280426 Cost 1.4131968524307013 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 500
Accuracy 0.02821601741015911 Cost 0.5616168330889195 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.5, Training Epoches: 10
Accuracy 0.027912624180316925 Cost 0.1818782378686592 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.1, Training Epoches: 10
Accuracy 0.027912622317671776 Cost 0.4417736807372421 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 20
Accuracy 0.027912622317671776 Cost 0.5459146539214998 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 50
Accuracy 0.027912622317671776 Cost 0.5382517543621361 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 1000
Accuracy 0.027912622317671776 Cost 0.8149904741439968 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 300
Accuracy 0.027912620455026627 Cost 0.16479486250318587 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 20
Accuracy 0.02760922536253929 Cost 0.4731877613812685 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 10
Accuracy 0.027002427726984024 Cost 0.22377759485971183 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 10
Accuracy 0.027002427726984024 Cost 0.65042320988141 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 200
Accuracy 0.027002427726984024 Cost 1.1902635172009468 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 400
Accuracy 0.027002425864338875 Cost 1.4797061206772923 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 200
Accuracy 0.02669903077185154 Cost 0.27249437803402543 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 100
Accuracy 0.02669903077185154 Cost 0.45743451826274395 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 200
Accuracy 0.026395633816719055 Cost 1.1471700947731733 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 500
Accuracy 0.026395631954073906 Cost 0.42461599805392325 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 400
Accuracy 0.026395631954073906 Cost 0.575727628543973 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 200
Accuracy 0.026395631954073906 Cost 1.201276745647192 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 300
Accuracy 0.02609223499894142 Cost 0.851116731762886 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 10
Accuracy 0.02609223499894142 Cost 1.176592658739537 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 50
Accuracy 0.02578883431851864 Cost 0.41392877337057143 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 500
Accuracy 0.02518204040825367 Cost 0.5000435109250247 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 500
Accuracy 0.02518203854560852 Cost 1.1764278672635555 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.6, Training Epoches: 10
Accuracy 0.02457524463534355 Cost 0.27621247118804604 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.2, Training Epoches: 20
Accuracy 0.0236650500446558 Cost 1.4054678222164512 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 300
Accuracy 0.02366504818201065 Cost 0.7633497109636664 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 400
Accuracy 0.023361651226878166 Cost 0.6155137789901346 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.5, Training Epoches: 700
Accuracy 0.022451456636190414 Cost 0.48584580956958234 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.4, Training Epoches: 400
Accuracy 0.022451456636190414 Cost 0.17102102364879102 Optimizer <class 'tensorflow.python.training.adadelta.AdadeltaOptimizer'> Learning Rate 0.01, Training Epoches: 10
Accuracy 0.02214805968105793 Cost 0.45892273588106036 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.3, Training Epoches: 100
Accuracy 0.02214805781841278 Cost 1.3228485425934196 Optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'> Learning Rate 0.7, Training Epoches: 700
Accuracy 0.008191747590899467 Cost 1.4164626989513636 Optimizer <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'> Learning Rate 0.7, Training Epoches: 10
